---
sidebar_position: 7
---
# S3
## Simple Storage Service
Object storage service или сервис хранения объектов, который можно бескочечно масштабировать.
### Use cases
- Backup and storage;
- Disaster Recovery (при перемещении данных в другой регион);
- Archive;
- Hybrid Cloud storage (при имении хранилища на собственных серверах, но не хочется расширять их в облако);
- Application hosting;
- Media hosting;
- Data lakes & big data analytics;
- Software delivery;
- Static website.

## Buckets
S3 позволяет хранить объекты (файлы) в "бакетах" (директориях). Бакеты определяются на уровне региона.
:::caution

Бакеты должны иметь **globally unique name** (среди всех регионов и всех аккаунтов).

:::

## Objects
Объекты (файлы) имееют ключ (`Key`) - Full path of the file:
* s3://my-bucket - `Top-level directory`
* /my_folder_1/another_folder/file.txt - `Key`
  * /my_folder_1/another_folder - `Prefix`
  * /file.txt - `Object name`

Также `Object` имеет `Metadata`, `Tags`, `Version ID`.
:::info

Max `Object` size is `5TB` (5000 GB) - это за один раз, но можно порционно выгружать большие файлы с помощью функции `multi-part upload`.

:::

## Security 
Из базового - это `User-Based`, где указывается `IAM Policy` - какие API вызовы будут доступны конкретному пользователю.

`Resource-Based` - это `Bucket Policies`, где указываются правила напрямую из S3 консоли. Также в `Resource-Based` входит Object/Bucket Access Control List (`ACL`) - безопасность такая.
### Bucket Policies
Это JSON-based полиси:
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "statement1",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::123456789012:user/Dave"
      },
      "Action": [
        "s3:GetObjectVersion",
        "s3:GetBucketAcl"
      ],
      "Resource": [
        "arn:aws:s3:::DOC-EXAMPLE-BUCKET1",
	 	"arn:aws:s3:::DOC-EXAMPLE-BUCKET1/*"
      ]
    },
    {
      "Sid": "statement2",
      "Effect": "Deny",
      "Principal": {
        "AWS": "arn:aws:iam::123456789012:user/Dave"
      },
      "Action": [
        "s3:DeleteObject",
        "s3:DeleteObjectVersion",
        "s3:PutLifecycleConfiguration"
      ],
      "Resource": [
        "arn:aws:s3:::DOC-EXAMPLE-BUCKET1",
	    "arn:aws:s3:::DOC-EXAMPLE-BUCKET1/*"
      ]
    }
  ]
}

// Мы явно отказали пользователю Dave в разрешении DELETE Object. Явный отказ всегда заменяет любое другое предоставленное разрешение.
```
Чтобы явно запретить пользователям или учетным записям удалять объекты, необходимо добавить в политику корзины следующие действия: разрешения `s3:DeleteObject`, `s3:DeleteObjectVersion` и `s3:PutLifecycleConfiguration`. Все три действия необходимы, поскольку вы можете удалять объекты либо путем явного вызова **DELETE Object API**, либо путем настройки их жизненного цикла (см. Управление жизненным циклом хранилища), чтобы Amazon S3 мог удалять объекты по истечении срока их жизни.

## Static Website Hosting
Для этого надо перевести бакет в режим `Public`, а также подрубить функцию `Static Website Hosting`, где также указываем `index.html` и `error.html` (можно еще `Redirection rules`, но это опционально).

## Versioning
Эту фичу также надо отдельно активировать на уровне бакета. Фича дает возможноть версионирования файлов, то есть хранение одного и того же файла, но с разными `Version ID` который перезаписывает старую версию. Старые версии можно восстанавливать.

## Replication
Это процесс, под которым понимается копирование данных из одного источника на другой (или на множество других) и наоборот.`Versioning` must be enabled on both the source and destination buckets.

Бакеты могут быть в разных AWS аккаунтах, копирование происходит асинхронно (in the background).

### Cross-Region Replication (CRR)
Используются два разных региона. Доступ с меньшей задержкой.

### Same-Region Replication (SRR)
Используются один и тот же регион. Подходит для агрегации логов или при репликации между продакшеном и тестовім аккаунтами вживую.

## Storage Classes
Durability and Availability (долговечность и доступность):
- **Durability** показывает статистику потери объекта в **S3**. Естественно, у Амазона этот показатель очень высокий - шанс потери объекта очень мал. Одинаков для всех `Storage Classes`.
- **Availability** измеряет, насколько доступный сервис. Зависит от `Storage Classes`.

### S3 Standard - General purpose
Подходит для BigData аналитики, мобильных или игровых приложений, дистрибуции контента и тд.
- 99.99% Availability;
- Используется для частого доступа к данным;
- Низная задержка и высокая пропускная способность;
- Устранение двух одновременных сбоев объектов.

### S3 Infrequent Access
`S3 Standard-IA` предназначен для данных, к которым доступ осуществляется реже, но при необходимости требуется быстрый доступ - это стоит дешевле, чем `S3 Standard`. Подходит под бекапы или для *Disaster Recovery*, имеет 99,9% Availability.

Есть еще `One Zone-Infrequent Access (S3 One Zone-IA)`, который имеет `99,9% Durability` в одной **AZ**, `99,5% Availability` и данные умирают если **AZ** умерло. Подходит для второстепенных бекапов или данных, которые вы сможете пересоздать.

### S3 Glacier
S3 Glacier — это безопасный, надежный и недорогой класс хранилища для архивирования данных.

- **S3 Glacier Instant Retrieval**: класс архивного хранилища, обеспечивающий самое дешевое хранилище для долгоживущих данных, доступ к которым осуществляется редко и требующих извлечения за миллисекунды;
- **S3 Glacier Flexible Retrieval**: обеспечивает надежность данных на уровне 99,999999999% (11 девяток) и доступность на уровне 99,99% за счет избыточного хранения данных в нескольких физически разделенных зонах доступности AWS в течение определенного года;
- **S3 Glacier Deep Archive**: обеспечивает самое дешевое хранилище, стоимость которого до 75 % ниже (по сравнению с S3 Glacier Flexible Retrival), для долгоживущих архивных данных, доступ к которым осуществляется реже одного раза в год и которые извлекаются асинхронно.

### S3 Intelligent-Tiering
Обеспечивает автоматическую экономию затрат на хранение данных на трех уровнях доступа с малой задержкой и высокой пропускной способностью. За небольшую ежемесячную плату за мониторинг и автоматизацию объектов S3 Intelligent-Tiering отслеживает шаблоны доступа и автоматически перемещает объекты, к которым не было доступа, на более дешевые уровни доступа.